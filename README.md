## Interpreting Deep Learning: An Application of Explainable AI (XAI) in Satellite Image Classification

The following is a focused exploration of how deep learning models perceive and prioritize features in satellite imagery.  

Using **Convolutional Neural Networks (CNNs)**, **Transfer Learning**, and **Integrated Gradients**, this report applies **Explainable AI (XAI)** techniques to uncover what drives a model’s decisions—and what it “sees” when it looks at the Earth from space.

> The report blends performance analysis with interpretability, offering a lens into the inner logic of neural networks.

![1](./assets/1.jpg)
![2](./assets/2.jpg)
![3](./assets/3.jpg)
![4](./assets/4.jpg)
![5](./assets/5.jpg)

📄 [Click to download the full report PDF](./Final-Report-645-YeneIrvine.pdf)

🔗 **Trained models available via Google Drive**:  
[Access models →](https://drive.google.com/drive/folders/1H6Epfbe-EJdkYNWIMq4t5ad221tHED8E?usp=sharing)

